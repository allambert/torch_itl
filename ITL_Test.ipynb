{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_itl import model, sampler, cost, kernel, estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths and load model config / ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set trained model paths\n",
    "base_experiment_path = './LS_Experiments'\n",
    "model_name = 'Rafd_itl_model_20201118-134437'\n",
    "\n",
    "# get model config and ckpt\n",
    "base_model_path = os.path.join(base_experiment_path, model_name, 'model/')\n",
    "for fname in os.listdir(base_model_path):\n",
    "    if ('config' in fname) and (fname.split('.')[-1] == 'json'):\n",
    "        model_config_path = os.path.join(base_model_path, fname)\n",
    "    elif ('ckpt' in fname) and (fname.split('.')[-1] == 'pt'):\n",
    "        model_ckpt_path = os.path.join(base_model_path, fname)\n",
    "    else:\n",
    "        print(fname, 'does not exist')\n",
    "print(model_config_path, model_ckpt_path)\n",
    "\n",
    "# load ckpt and json\n",
    "with open(model_config_path, 'r') as f:\n",
    "    model_config = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# Reading input/output data\n",
    "# ----------------------------------\n",
    "dataset = model_config['Data']['dataset']  \n",
    "theta_type = model_config['Data']['theta_type']  \n",
    "inc_neutral = model_config['Data']['include_neutral']  \n",
    "use_facealigner = True if model_config['Data']['input_data_version'] == 'facealigner' else False\n",
    "\n",
    "data_path = './datasets/Rafd_Aligned/Rafd_LANDMARKS'  # set data path\n",
    "if dataset == 'Rafd':\n",
    "    # dirty hack only used to get Rafd speaker ids, not continuously ordered\n",
    "    data_csv_path = '/home/mlpboon/Downloads/Rafd/Rafd.csv'\n",
    "\n",
    "print('Reading data')\n",
    "if use_facealigner:\n",
    "    if dataset == 'KDEF':\n",
    "        from datasets.datasets import kdef_landmarks_facealigner\n",
    "        x_train, y_train, x_test, y_test, train_list, test_list = \\\n",
    "            kdef_landmarks_facealigner(data_path, inc_neutral=inc_neutral)\n",
    "    elif dataset == 'Rafd':\n",
    "        from datasets.datasets import rafd_landmarks_facealigner\n",
    "        x_train, y_train, x_test, y_test, train_list, test_list = \\\n",
    "            rafd_landmarks_facealigner(data_path, data_csv_path, inc_neutral=inc_neutral)\n",
    "else:\n",
    "    from datasets.datasets import import_kdef_landmark_synthesis\n",
    "    x_train, y_train, x_test, y_test = import_kdef_landmark_synthesis(dtype=input_data_version)\n",
    "\n",
    "n = x_train.shape[0]\n",
    "m = y_train.shape[1]\n",
    "nf = y_train.shape[2]\n",
    "print('data dimensions', n, m, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ITL model\n",
    "assert model_config['Kernels']['kernel_input_learnable'] == False\n",
    "kernel_input = kernel.Gaussian(model_config['Kernels']['gamma_inp'])\n",
    "kernel_output = kernel.Gaussian(model_config['Kernels']['gamma_out'])\n",
    "kernel_freq = np.eye(nf) # can be added to ckpt or manually set as np.load(kernel_file)\n",
    "\n",
    "# define emotion sampler - this can also be added to ckpt\n",
    "if model_config['Data']['theta_type'] == 'aff':\n",
    "    from datasets.datasets import import_affectnet_va_embedding\n",
    "    affect_net_csv_path = './utils/landmark_utils/validation.csv'  # to be set if theta_type == 'aff'\n",
    "    aff_emo_dict = import_affectnet_va_embedding(affect_net_csv_path)\n",
    "\n",
    "    sampler_ = sampler.CircularSampler(data=dataset+theta_type,\n",
    "                                       inc_neutral=inc_neutral,\n",
    "                                       sample_dict=aff_emo_dict)\n",
    "elif theta_type == '':\n",
    "    sampler_ = sampler.CircularSampler(data=dataset,\n",
    "                                       inc_neutral=inc_neutral)\n",
    "sampler_.m = m\n",
    "\n",
    "itl_model = model.SpeechSynthesisKernelModel(kernel_input, kernel_output,\n",
    "                                             kernel_freq=torch.from_numpy(kernel_freq).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(model_ckpt_path)\n",
    "itl_model.test_mode(x_train=x_train, thetas=sampler_.sample(m), alpha=ckpt['itl_alpha'])\n",
    "pred_test = itl_model.forward(x_test, sampler_.sample(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_output = pred_test*128\n",
    "check_output[0,0].reshape(68,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt_x = x_test[0].numpy().reshape(68, 2)\n",
    "plt_xt = pred_test[1, 4].detach().numpy().reshape(68, 2)\n",
    "if use_facealigner:\n",
    "    plt_x = plt_x * 128\n",
    "    plt_xt = plt_xt * 128\n",
    "plt_uv = plt_xt - plt_x\n",
    "plt.quiver(plt_x[:, 0], plt_x[:, 1], plt_uv[:, 0], plt_uv[:, 1], angles='xy')\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_space_sampling(theta1, theta2, num_samples):\n",
    "    angle1 = np.arctan2(theta1[1], theta1[0])\n",
    "    angle2 = np.arctan2(theta2[1], theta2[0])\n",
    "    angle1 = angle1 if angle1>=0 else angle1+(2*np.pi)\n",
    "    angle2 = angle2 if angle2>=0 else angle2+(2*np.pi)\n",
    "    \n",
    "    reverse = False\n",
    "    if angle1>angle2:\n",
    "        start = angle2; end = angle1\n",
    "        reverse = True\n",
    "    else:\n",
    "        start = angle1; end = angle2\n",
    "        \n",
    "    sampled_angles = np.linspace(start=start, stop=end, num=num_samples, endpoint=True)\n",
    "    sample_coords = np.vstack((np.cos(sampled_angles), np.sin(sampled_angles))).T\n",
    "    \n",
    "    if reverse:\n",
    "        return np.flipud(sample_coords)\n",
    "    else:\n",
    "        return sample_coords\n",
    "\n",
    "class EdgeMap(object):\n",
    "    def __init__(self, out_res, num_parts=3):\n",
    "        self.out_res = out_res\n",
    "        self.num_parts = num_parts\n",
    "        self.groups = [\n",
    "            [np.arange(0, 17, 1), 255],\n",
    "            [np.arange(17, 22, 1), 255],\n",
    "            [np.arange(22, 27, 1), 255],\n",
    "            [np.arange(27, 31, 1), 255],\n",
    "            [np.arange(31, 36, 1), 255],\n",
    "            [list(np.arange(36, 42, 1)) + [36], 255],\n",
    "            [list(np.arange(42, 48, 1)) + [42], 255],\n",
    "            [list(np.arange(48, 60, 1)) + [48], 255],\n",
    "            [list(np.arange(60, 68, 1)) + [60], 255]\n",
    "        ]\n",
    "\n",
    "    def __call__(self, shape):\n",
    "        image = np.zeros((self.out_res, self.out_res, self.num_parts), dtype=np.float32)\n",
    "        for g in self.groups:\n",
    "            for i in range(len(g[0]) - 1):\n",
    "                start = int(shape[g[0][i]][0]), int(shape[g[0][i]][1])\n",
    "                end = int(shape[g[0][i + 1]][0]), int(shape[g[0][i + 1]][1])\n",
    "                cv2.line(image, start, end, g[1], 1)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "ckpt = torch.load(model_ckpt_path)\n",
    "itl_model.test_mode(x_train=x_train, thetas=sampler_.sample(m), alpha=ckpt['itl_alpha'])\n",
    "sampled_emotions = emotion_space_sampling(aff_emo_dict['Fear'], aff_emo_dict['Anger'], 10)\n",
    "EM = EdgeMap(out_res=128, num_parts=1)\n",
    "for i in range(len(sampled_emotions)):\n",
    "    pred_test = itl_model.forward(x_test, torch.from_numpy(sampled_emotions[i][np.newaxis]).float())\n",
    "    im_em = EM(pred_test[0, 0].detach().numpy().reshape(68,2)*128)\n",
    "    plt.imshow(np.squeeze(im_em))\n",
    "    plt.pause(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

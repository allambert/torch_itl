{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_itl import model, sampler, cost, kernel, estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths and load model config / ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set trained model paths\n",
    "base_experiment_path = './LS_Experiments/KDEF_single'\n",
    "model_name = 'KDEF_NE_itl_model_split1_CF'\n",
    "\n",
    "# get model config and ckpt\n",
    "base_model_path = os.path.join(base_experiment_path, model_name, 'model/')\n",
    "for fname in os.listdir(base_model_path):\n",
    "    if ('config' in fname) and (fname.split('.')[-1] == 'json'):\n",
    "        model_config_path = os.path.join(base_model_path, fname)\n",
    "    elif ('ckpt' in fname) and (fname.split('.')[-1] == 'pt'):\n",
    "        model_ckpt_path = os.path.join(base_model_path, fname)\n",
    "    else:\n",
    "        print(fname, 'does not exist')\n",
    "print(model_config_path, model_ckpt_path)\n",
    "\n",
    "# load ckpt and json\n",
    "with open(model_config_path, 'r') as f:\n",
    "    model_config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# Reading input/output data\n",
    "# ----------------------------------\n",
    "dataset = model_config['Data']['dataset']  \n",
    "theta_type = model_config['Data']['theta_type']\n",
    "inp_emotion = model_config['Data']['inpu_emotion'] \n",
    "inc_neutral = model_config['Data']['include_emotion']  \n",
    "use_facealigner = True if model_config['Data']['input_data_version'] == 'facealigner' else False\n",
    "\n",
    "data_path = './datasets/' + dataset + '_Aligned/' + dataset +'_LANDMARKS'  # set data path\n",
    "if dataset == 'Rafd':\n",
    "    # dirty hack only used to get Rafd speaker ids, not continuously ordered\n",
    "    data_csv_path = '/home/mlpboon/Downloads/Rafd/Rafd.csv'\n",
    "\n",
    "print('Reading data')\n",
    "if use_facealigner:\n",
    "    if dataset == 'KDEF':\n",
    "        from datasets.datasets import kdef_landmarks_facealigner\n",
    "        x_train, y_train, x_test, y_test, train_list, test_list = \\\n",
    "            kdef_landmarks_facealigner(data_path, inp_emotion=inp_emotion, inc_emotion=inc_neutral)\n",
    "    elif dataset == 'Rafd':\n",
    "        from datasets.datasets import rafd_landmarks_facealigner\n",
    "        x_train, y_train, x_test, y_test, train_list, test_list = \\\n",
    "            rafd_landmarks_facealigner(data_path, data_csv_path, inc_emotion=inc_neutral)\n",
    "else:\n",
    "    from datasets.datasets import import_kdef_landmark_synthesis\n",
    "    x_train, y_train, x_test, y_test = import_kdef_landmark_synthesis(dtype=input_data_version)\n",
    "\n",
    "n = x_train.shape[0]\n",
    "m = y_train.shape[1]\n",
    "nf = y_train.shape[2]\n",
    "print('data dimensions', n, m, nf, inp_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ITL model\n",
    "assert model_config['Kernels']['kernel_input_learnable'] == False\n",
    "kernel_input = kernel.Gaussian(model_config['Kernels']['gamma_inp'])\n",
    "kernel_output = kernel.Gaussian(model_config['Kernels']['gamma_out'])\n",
    "kernel_freq = np.eye(nf) # can be added to ckpt or manually set as np.load(kernel_file)\n",
    "\n",
    "# define emotion sampler - this can also be added to ckpt\n",
    "if model_config['Data']['theta_type'] == 'aff':\n",
    "    from datasets.datasets import import_affectnet_va_embedding\n",
    "    affect_net_csv_path = ''  # to be set if theta_type == 'aff'\n",
    "    aff_emo_dict = import_affectnet_va_embedding(affect_net_csv_path)\n",
    "    \n",
    "    if dataset == 'KDEF':\n",
    "        aff_emo_match = {'NE': 'Neutral',\n",
    "                         'HA': 'Happy',\n",
    "                         'SA': 'Sad',\n",
    "                         'SU': 'Surprise',\n",
    "                         'AF': 'Fear',\n",
    "                         'DI': 'Disgust',\n",
    "                         'AN': 'Anger',\n",
    "                         }\n",
    "    elif dataset == 'Rafd':\n",
    "        aff_emo_match = {'neutral': 'Neutral',\n",
    "                         'happy': 'Happy',\n",
    "                         'sad': 'Sad',\n",
    "                         'surprised': 'Surprise',\n",
    "                         'fearful': 'Fear',\n",
    "                         'disgusted': 'Disgust',\n",
    "                         'angry': 'Anger',\n",
    "                         'contemptous': 'Contempt'\n",
    "                         }    \n",
    "    \n",
    "    \n",
    "    sampler_ = sampler.CircularSampler(data=dataset+theta_type,\n",
    "                                       inp_emotion=aff_emo_match[inp_emotion],\n",
    "                                       inc_emotion=inc_neutral,\n",
    "                                       sample_dict=aff_emo_dict)\n",
    "elif theta_type == '':\n",
    "    sampler_ = sampler.CircularSampler(data=dataset,\n",
    "                                       inc_neutral=inc_neutral)\n",
    "sampler_.m = m\n",
    "\n",
    "itl_model = model.SpeechSynthesisKernelModel(kernel_input, kernel_output,\n",
    "                                             kernel_freq=torch.from_numpy(kernel_freq).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(model_ckpt_path)\n",
    "itl_model.test_mode(x_train=x_train, thetas=sampler_.sample(m), alpha=ckpt['itl_alpha'])\n",
    "pred_test = itl_model.forward(x_test, sampler_.sample(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cost\n",
    "cost_pred = cost.speech_synth_loss(y_test, pred_test, sampler_.sample(m))\n",
    "print('cost test:', cost_pred)\n",
    "\n",
    "# compute expected euclidean distance between samples and mean for each emotion\n",
    "var_gt_em = 0\n",
    "var_test_em = 0\n",
    "var_gt = 0\n",
    "var_test = 0\n",
    "for i in range(m):\n",
    "    var_gt_em = np.sum(np.var(y_test[:,i,:].numpy(), axis=0))\n",
    "    var_test_em = np.sum(np.var(pred_test[:,i,:].numpy(), axis=0))\n",
    "    var_gt += var_gt_em\n",
    "    var_test += var_test_em\n",
    "    print('{:d}, {:.3f}, {:.3f}'.format(i, var_gt_em, var_test_em))\n",
    "print('{:.3f}, {:.3f}'.format(var_gt/m, var_test/m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_sampling(theta1, theta2, num_samples):\n",
    "    angle1 = np.arctan2(theta1[1], theta1[0])\n",
    "    angle2 = np.arctan2(theta2[1], theta2[0])\n",
    "    angle1 = angle1 if angle1>=0 else angle1+(2*np.pi)\n",
    "    angle2 = angle2 if angle2>=0 else angle2+(2*np.pi)\n",
    "    \n",
    "    reverse = False\n",
    "    if angle1>angle2:\n",
    "        start = angle2; end = angle1\n",
    "        reverse = True\n",
    "    else:\n",
    "        start = angle1; end = angle2\n",
    "        \n",
    "    sampled_angles = np.linspace(start=start, stop=end, num=num_samples, endpoint=True)\n",
    "    sample_coords = np.vstack((np.cos(sampled_angles), np.sin(sampled_angles))).T\n",
    "    \n",
    "    if reverse:\n",
    "        return np.flipud(sample_coords)\n",
    "    else:\n",
    "        return sample_coords, sampled_angles\n",
    "\n",
    "def radial_sampling(theta, num_samples):\n",
    "    angle = np.arctan2(theta[1], theta[0])\n",
    "    sampled_radii = np.linspace(start=0, stop=1, num=num_samples, endpoint=True)\n",
    "    sample_coords = np.vstack((sampled_radii*np.cos(angle), sampled_radii*np.sin(angle))).T\n",
    "    return sample_coords, sampled_radii\n",
    "\n",
    "\n",
    "class EdgeMap(object):\n",
    "    def __init__(self, out_res, num_parts=3):\n",
    "        self.out_res = out_res\n",
    "        self.num_parts = num_parts\n",
    "        self.groups = [\n",
    "            [np.arange(0, 17, 1), 255],\n",
    "            [np.arange(17, 22, 1), 255],\n",
    "            [np.arange(22, 27, 1), 255],\n",
    "            [np.arange(27, 31, 1), 255],\n",
    "            [np.arange(31, 36, 1), 255],\n",
    "            [list(np.arange(36, 42, 1)) + [36], 255],\n",
    "            [list(np.arange(42, 48, 1)) + [42], 255],\n",
    "            [list(np.arange(48, 60, 1)) + [48], 255],\n",
    "            [list(np.arange(60, 68, 1)) + [60], 255]\n",
    "        ]\n",
    "\n",
    "    def __call__(self, shape):\n",
    "        image = np.zeros((self.out_res, self.out_res, self.num_parts), dtype=np.float32)\n",
    "        for g in self.groups:\n",
    "            for i in range(len(g[0]) - 1):\n",
    "                start = int(shape[g[0][i]][0]), int(shape[g[0][i]][1])\n",
    "                end = int(shape[g[0][i + 1]][0]), int(shape[g[0][i + 1]][1])\n",
    "                cv2.line(image, start, end, g[1], 1)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "sampling_type = 'circular'\n",
    "num_samples = 180\n",
    "ckpt = torch.load(model_ckpt_path)\n",
    "itl_model.test_mode(x_train=x_train, thetas=sampler_.sample(m), alpha=ckpt['itl_alpha'])\n",
    "if sampling_type == 'circular':\n",
    "    sampled_emotions, sampled_angles = circular_sampling(aff_emo_dict['Happy'], aff_emo_dict['Sad'], num_samples)\n",
    "    print(sampled_angles)\n",
    "elif sampling_type == 'radial':\n",
    "    sampled_emotions, sampled_radii = radial_sampling(aff_emo_dict['Fear'], num_samples)\n",
    "    print(sampled_radii)\n",
    "EM = EdgeMap(out_res=128, num_parts=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# for i in range(len(sampled_emotions)):\n",
    "#     pred_test = itl_model.forward(x_test, torch.from_numpy(sampled_emotions[i][np.newaxis]).float())\n",
    "#     im_em = EM(pred_test[0, 0].detach().numpy().reshape(68,2)*128)\n",
    "#     plt.imshow(np.squeeze(im_em))\n",
    "#     plt.pause(0.5)\n",
    "    \n",
    "output_path_cont_gen = './utils/plot_utils/visualizations/continuous_control/circ_video_kdef/happy_sad'\n",
    "if not os.path.exists(output_path_cont_gen):\n",
    "    os.makedirs(output_path_cont_gen)\n",
    "for i in range(len(sampled_emotions)):\n",
    "    pred_test = itl_model.forward(x_test, torch.from_numpy(sampled_emotions[i][np.newaxis]).float())\n",
    "    im_em = EM(pred_test[0, 0].detach().numpy().reshape(68,2)*128)\n",
    "    cv2.imwrite(os.path.join(output_path_cont_gen, str(i).zfill(3)+'.jpg'), im_em)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

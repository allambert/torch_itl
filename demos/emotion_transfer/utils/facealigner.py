from collections import OrderedDict
import subprocess
import numpy as np
import cv2
import os


# For dlibâ€™s 68-point facial landmark detector:
FACIAL_LANDMARKS_68_IDXS = OrderedDict([
    ("mouth", (48, 68)),
    ("inner_mouth", (60, 68)),
    ("right_eyebrow", (17, 22)),
    ("left_eyebrow", (22, 27)),
    ("right_eye", (36, 42)),
    ("left_eye", (42, 48)),
    ("nose", (27, 36)),
    ("jaw", (0, 17))
])


class FaceAligner:
    """
    Modified from python library imutils
    """

    def __init__(self, desiredLeftEye=(0.35, 0.35),
                 desiredFaceWidth=256, desiredFaceHeight=None):
        # store the facial landmark predictor, desired output left
        # eye position, and desired output face width + height

        self.desiredLeftEye = desiredLeftEye
        self.desiredFaceWidth = desiredFaceWidth
        self.desiredFaceHeight = desiredFaceHeight

        # if the desired face height is None, set it to be the
        # desired face width (normal behavior)
        if self.desiredFaceHeight is None:
            self.desiredFaceHeight = self.desiredFaceWidth

    def align(self, image, shape):
        if len(shape) == 68:
            # extract the left and right eye (x, y)-coordinates
            (lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS["left_eye"]
            (rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS["right_eye"]

        leftEyePts = shape[lStart:lEnd]
        rightEyePts = shape[rStart:rEnd]

        # compute the center of mass for each eye
        leftEyeCenter = leftEyePts.mean(axis=0).astype("int")
        rightEyeCenter = rightEyePts.mean(axis=0).astype("int")

        # compute the angle between the eye centroids
        dY = rightEyeCenter[1] - leftEyeCenter[1]
        dX = rightEyeCenter[0] - leftEyeCenter[0]
        angle = np.degrees(np.arctan2(dY, dX)) - 180

        # compute the desired right eye x-coordinate based on the
        # desired x-coordinate of the left eye
        desiredRightEyeX = 1.0 - self.desiredLeftEye[0]

        # determine the scale of the new resulting image by taking
        # the ratio of the distance between eyes in the *current*
        # image to the ratio of distance between eyes in the
        # *desired* image
        dist = np.sqrt((dX ** 2) + (dY ** 2))
        desiredDist = (desiredRightEyeX - self.desiredLeftEye[0])
        desiredDist *= self.desiredFaceWidth
        scale = desiredDist / dist

        # compute center (x, y)-coordinates (i.e., the median point)
        # between the two eyes in the input image
        eyesCenter = ((leftEyeCenter[0] + rightEyeCenter[0]) // 2,
                      (leftEyeCenter[1] + rightEyeCenter[1]) // 2)

        # grab the rotation matrix for rotating and scaling the face
        M = cv2.getRotationMatrix2D(eyesCenter, angle, scale)

        # update the translation component of the matrix
        tX = self.desiredFaceWidth * 0.5
        tY = self.desiredFaceHeight * self.desiredLeftEye[1]
        M[0, 2] += (tX - eyesCenter[0])
        M[1, 2] += (tY - eyesCenter[1])

        # apply the affine transformation
        (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)
        output = cv2.warpAffine(image, M, (w, h),
                                flags=cv2.INTER_CUBIC)
        output_lnd = cv2.transform(shape[np.newaxis], M)
        # return the aligned face and lnd
        return output, np.squeeze(output_lnd)


def list_and_landmarks(dataset, data_dir, lnd_dir, paths_txt, predictor_path):

    # generate frontal faces list according to dataset
    img_list = []
    if dataset == 'KDEF':
        for dir, subdir, filenames in os.walk(data_dir):
            for f in filenames:
                if f.endswith('S.JPG'):
                    img_list.append(os.path.join(dir, f))
    elif dataset == 'Rafd':
        for img in sorted(os.listdir(data_dir)):
            print(img)
            if img.split('.')[-1].lower() == 'jpg':
                fname_part = img.split('.')[0].split('_')
                print(fname_part)
                if fname_part[5] == 'frontal' and fname_part[0][4:] == '090':
                    img_list.append(os.path.join(data_dir, img))

    with open(paths_txt, 'w') as f:
        for fpath in img_list:
            f.write('{}\n'.format(fpath))

    # get landmarks from dlib
    if not os.path.exists(predictor_path):
        print('Landmarks predictor does not exist.')
    else:
        dlib_cmd = ' '.join(['python dlib_landmarks.py',
                             predictor_path, paths_txt, lnd_dir])
        with subprocess.Popen(
                dlib_cmd, shell=True, stdout=subprocess.PIPE) as cmd:
            for line in cmd.stdout:
                print(line)
    return img_list


def data_preprocess(dataset, data_dir, dest_base_dir, predictor_path):
    """
    Parameters
    ----------
    dataset : str
        KDEF or Rafd, dataset names
    data_dir: str
        path to data directory to fetch images
    dest_base_dir:
        directory to store all outputs
    predictor_path:
        predictor for computing dlib landmarks
        Download from http://dlib.net/files/shape_predictor_68_face_\
                                        landmarks.dat.bz2

    Returns
    -------
    Saves all dlib landmarks, aligned images/landmarks in dedicated folders on
        dest_base_dir
    """

    print('COMPUTING LANDMARKS')
    # create file list, compute landmarks and return with list for alignment
    lnd_dir = os.path.join(dest_base_dir, dataset + '_LANDMARKS')
    paths_txt = os.path.join(dest_base_dir, dataset + '_frontal_list.txt')
    if not os.path.exists(lnd_dir):
        os.makedirs(lnd_dir)
    img_list = list_and_landmarks(
        dataset, data_dir, lnd_dir, paths_txt, predictor_path)

    print('PERFORMING ALIGNMENT')
    # init aligner
    fa = FaceAligner(desiredFaceWidth=128)

    # destination directory structure
    dest_parent_folder_path = os.path.join(dest_base_dir, dataset + '_Aligned')
    dest_sub_folder_datapath = os.path.join(dest_parent_folder_path, dataset)
    dest_sub_folder_lndpath = os.path.join(
        dest_parent_folder_path, dataset + '_LANDMARKS')

    if not os.path.exists(dest_parent_folder_path):
        os.makedirs(dest_sub_folder_datapath)
        os.makedirs(dest_sub_folder_lndpath)

    for index, row in enumerate(img_list):

        # read each image and landmarks
        # ----file paths
        im_path = row
        file_name = row.split('/')[-1].split('.')[0]
        lnd_file_path = os.path.join(lnd_dir, file_name + '.txt')

        # ----read_image
        image = cv2.imread(im_path)

        # get landmarks
        points = np.loadtxt(lnd_file_path).reshape(68, 2)

        # compute alignment
        image_aligned, points_aligned = fa.align(image, points)

        # store back in a folder structure similar to Rafd
        row_impath = os.path.join(dest_sub_folder_datapath, file_name + '.JPG')
        row_lndpath = os.path.join(dest_sub_folder_lndpath, file_name + '.txt')

        cv2.imwrite(row_impath, image_aligned)
        with open(row_lndpath, 'w') as file:
            for idx_l in range(68):
                file.write("{} {}\n".format(
                    points_aligned[idx_l, 0], points_aligned[idx_l, 1]))


if __name__ == "__main__":
    # DL from http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
    predictor_path = 'shape_predictor_68_face_landmarks.dat'

    dataset = 'KDEF'
    data_dir = 'PATH_TO_KDEF'
    dest_dir = 'DESTINATION PATH'

    # dataset = 'Rafd'
    # data_dir = 'PATH_TO_Rafd'
    # dest_dir = 'DESTINATION PATH'

    # change dest dir to be compatible with other scripts and store in
    # right location
    # dest_dir = '../../../torch_itl/datasets'

    data_preprocess(dataset, data_dir, dest_dir, predictor_path)
